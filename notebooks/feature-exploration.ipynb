{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from airflow.models import Variable\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from google.cloud import storage\n",
    "import tempfile\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_USER = Variable.get(\"POSTGRES_USER\")\n",
    "POSTGRES_PW = Variable.get(\"POSTGRES_PW\")\n",
    "POSTGRES_HOST = Variable.get(\"POSTGRES_HOST\")\n",
    "MSF_API_KEY = Variable.get(\"MSF_API_KEY\")\n",
    "postgres_connection_str = f'postgres+psycopg2://{POSTGRES_USER}:{POSTGRES_PW}@{POSTGRES_HOST}/nba'\n",
    "\n",
    "engine = sqlalchemy.create_engine(postgres_connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing game logs\n",
    "with engine.connect() as conn:\n",
    "    sqlq = \"\"\"\n",
    "        select\n",
    "              gm.season\n",
    "            , lu.game_id\n",
    "            , lu.team_id\n",
    "            , lu.player_id\n",
    "            , lu.type\n",
    "            , (lu.position like 'Starter%%') as starter\n",
    "            , lu.position\n",
    "            , gm.playedStatus\n",
    "        from lineups as lu\n",
    "        join games as gm\n",
    "            on lu.game_id = gm.id\n",
    "    \"\"\"\n",
    "    lineups = pd.read_sql(sqlq, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lineups\n",
    "    .groupby([\"type\", \"season\", \"playedstatus\"])\n",
    "    .aggregate(count=(\"game_id\", lambda x: x.count()), unique=(\"game_id\", lambda x: len(x.unique())))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare accuracy of expected vs actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lineups\n",
    "    .query(\"type == 'actual'\")\n",
    "    .drop(columns=[\"type\", \"playedstatus\"])\n",
    "    .merge(\n",
    "        lineups.query(\"type == 'expected'\"),\n",
    "        how=\"outer\",\n",
    "        on=[\"player_id\", \"game_id\", \"team_id\", \"season\"],\n",
    "        indicator=True,\n",
    "    )\n",
    "    .query(\"playedstatus == 'COMPLETED'\")\n",
    "    .pivot_table(\n",
    "        index=[\"season\"],\n",
    "        columns=[\"_merge\"],\n",
    "        values=[\"player_id\"],\n",
    "        aggfunc=\"count\",\n",
    "    )\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lineups\n",
    "    .query(\"type == 'actual'\")\n",
    "    .drop(columns=[\"type\", \"playedstatus\"])\n",
    "    .merge(\n",
    "        lineups.query(\"type == 'expected'\"),\n",
    "        how=\"outer\",\n",
    "        on=[\"player_id\", \"game_id\", \"team_id\", \"season\"],\n",
    "        indicator=True,\n",
    "    )\n",
    "    .query(\"playedstatus == 'COMPLETED'\")\n",
    "    .fillna({\"starter_x\": False, \"starter_y\": False})\n",
    "    .assign(\n",
    "        starter=lambda x: \n",
    "            [\n",
    "                {0: \"True non-starter\", 1: \"False non-starter\", 2: \"False starter\", 3: \"True starter\"}.get(x)\n",
    "                for x in x[\"starter_x\"].astype(int) + x[\"starter_y\"].astype(int) * 2\n",
    "            ]\n",
    "    )\n",
    "    .pivot_table(\n",
    "        index=[\"season\", \"_merge\"],\n",
    "        columns=[\"starter\"],\n",
    "        values=[\"player_id\"],\n",
    "        aggfunc=\"count\",\n",
    "    )\n",
    "    .apply(lambda x: x / x.sum(), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variables\n",
    "\n",
    "Targets: assists, 2pt fg, 3pt fg, ftm, rebounds, steals, blocks, turnovers, fantasy points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing game logs\n",
    "with engine.connect() as conn:\n",
    "    sqlq = \"\"\"\n",
    "        select\n",
    "            season, count(*)\n",
    "        from games as gm\n",
    "        where\n",
    "            not exists (\n",
    "                select * from player_gamelogs as gl\n",
    "                where gl.game_id = gm.id\n",
    "            )\n",
    "            and gm.playedStatus = 'COMPLETED'\n",
    "        group by 1\n",
    "        order by 1\n",
    "    \"\"\"\n",
    "    missing_games = pd.read_sql(sqlq, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player game stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    sqlq = \"\"\"\n",
    "        with stats as (\n",
    "            select\n",
    "                  gm.season\n",
    "                , lu.game_id\n",
    "                , lu.team_id\n",
    "                , lu.player_id\n",
    "                , lu.type\n",
    "                , (lu.position like 'Starter%%')::int as expected_starter\n",
    "                , lu.position as expected_position\n",
    "                , (alu.position like 'Starter%%')::int as starter\n",
    "                , alu.position as actual_position\n",
    "                , gm.starttime\n",
    "                , gm.playedstatus\n",
    "                , gl.stats_fieldgoals_fg2ptmade as fgm_2p\n",
    "                , gl.stats_fieldgoals_fg3ptmade as fgm_3p\n",
    "                , gl.stats_freethrows_ftmade as ftm\n",
    "                , gl.stats_rebounds_reb as trb\n",
    "                , gl.stats_offense_astpergame as ast\n",
    "                , gl.stats_defense_stl as stl\n",
    "                , gl.stats_defense_blk as blk\n",
    "                , gl.stats_defense_tov as tov\n",
    "                , gl.stats_miscellaneous_minseconds as secs\n",
    "            from lineups as lu\n",
    "            join public.games as gm\n",
    "                on lu.game_id = gm.id\n",
    "            left join public.player_gamelogs as gl\n",
    "                on lu.game_id = gl.game_id\n",
    "                and lu.team_id = gl.team_id\n",
    "                and lu.player_id = gl.player_id\n",
    "            left join public.lineups as alu\n",
    "                on lu.game_id = alu.game_id\n",
    "                and lu.team_id = alu.team_id\n",
    "                and lu.player_id = alu.player_id\n",
    "                and alu.type = 'actual'\n",
    "            where\n",
    "                lu.type = 'expected'\n",
    "        )\n",
    "        select\n",
    "            *\n",
    "            , coalesce(fgm_2p, 0) * 2\n",
    "                + coalesce(fgm_3p, 0) * 3\n",
    "                + coalesce(ftm, 0)\n",
    "                + coalesce(trb, 0) * 1.2\n",
    "                + coalesce(ast, 0) * 1.5\n",
    "                + coalesce(blk, 0) * 3\n",
    "                + coalesce(stl, 0) * 3\n",
    "                - coalesce(tov, 0)\n",
    "                as fanduel_fpts\n",
    "        from stats\n",
    "        order by player_id, starttime\n",
    "    \"\"\"\n",
    "    player_game_stats = pd.read_sql(sqlq, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_game_stats.groupby([\"season\", \"playedstatus\"]).apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends in stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avg(df, stats, window):\n",
    "    played_games = df.query(\"secs > 0\")\n",
    "    avgs = (\n",
    "        played_games\n",
    "        .groupby([\"player_id\"])\n",
    "        .apply(\n",
    "            lambda x: \n",
    "               x[stats]\n",
    "               .rolling(window=window)\n",
    "               .mean()\n",
    "        )\n",
    "    )\n",
    "    played_games = played_games[[\"player_id\", \"team_id\", \"game_id\"]].join(avgs)\n",
    "    \n",
    "    result = (\n",
    "        df[[\"player_id\", \"team_id\", \"game_id\"]]\n",
    "        .merge(played_games, on=[\"player_id\", \"team_id\", \"game_id\"], how=\"left\")\n",
    "        .groupby([\"player_id\"])\n",
    "        .apply(lambda x: x.shift(1)[stats].fillna(method=\"ffill\"))\n",
    "        .rename(columns=lambda col: f\"{col}_{window}g_avg\")\n",
    "    )\n",
    "    \n",
    "    return df[[\"player_id\", \"team_id\", \"game_id\"]].join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['fgm_2p', 'fgm_3p', 'ftm', 'trb', 'ast', 'stl', 'blk', 'tov', 'fanduel_fpts', 'secs']\n",
    "last_game, rolling_3gm, rolling_9gm, rolling_27gm = (\n",
    "    rolling_avg(player_game_stats, columns, win)\n",
    "    for win in (1, 3, 9, 27)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opponent allowed stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team game stats\n",
    "# rolling average game stats\n",
    "# joined to player-game data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: assert that all dfs being joined have the same number of rows, in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = (\n",
    "    player_game_stats\n",
    "    .join(last_game.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]))\n",
    "    .join(rolling_3gm.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]))\n",
    "    .join(rolling_9gm.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]))\n",
    "    .join(rolling_27gm.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]))\n",
    "    .loc[lambda x: x[\"season\"] != '2016-2017-regular']  # discard 2016 season as a warm start for trending metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_games = combined.query(\"playedstatus == 'COMPLETED'\")[\"game_id\"].unique()\n",
    "upcoming_games = combined.query(\"playedstatus == 'UNPLAYED'\")[\"game_id\"].unique()\n",
    "np.random.shuffle(completed_games)\n",
    "\n",
    "eval_games = completed_games[0:len(completed_games)//10]\n",
    "test_games = completed_games[len(completed_games)//10:len(completed_games)//5]\n",
    "train_games = completed_games[len(completed_games)//5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = combined.loc[lambda x: x[\"game_id\"].isin(train_games)]\n",
    "train_pool = Pool(\n",
    "    data=train_df.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]),\n",
    "    label=train_df[\"fanduel_fpts\"],\n",
    ")\n",
    "\n",
    "eval_df = combined.loc[lambda x: x[\"game_id\"].isin(eval_games)]\n",
    "eval_pool = Pool(\n",
    "    data=eval_df.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]),\n",
    "    label=eval_df[\"fanduel_fpts\"],\n",
    ")\n",
    "\n",
    "test_df = combined.loc[lambda x: x[\"game_id\"].isin(test_games)]\n",
    "test_pool = Pool(\n",
    "    data=test_df.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]),\n",
    "    label=test_df[\"fanduel_fpts\"],\n",
    ")\n",
    "\n",
    "model = CatBoostRegressor()\n",
    "model = model.fit(train_pool, eval_set=eval_pool, verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as file:\n",
    "    model.save_model(file.name)\n",
    "    upload_blob(\"airjordan-models\", file.name, \"fanduel_fpts_model.cbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.assign(prediction=model.predict(test_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.plot(x=\"fanduel_fpts\", y=\"prediction\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Upcoming games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(upcoming_games) > 0, \"Must have at least one upcoming game\"\n",
    "upcoming_df = combined.loc[lambda x: x[\"game_id\"].isin(upcoming_games)]\n",
    "upcoming_pool = Pool(\n",
    "    data=upcoming_df.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]),\n",
    ")\n",
    "\n",
    "upcoming_df = upcoming_df.assign(prediction=model.predict(upcoming_pool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    upcoming_df.to_sql(\"dfs_model_features\", conn, index=False, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that results match using saved model and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "    # destination_file_name = \"local/path/to/file\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Blob {} downloaded to {}.\".format(\n",
    "            source_blob_name, destination_file_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as file:\n",
    "    download_blob(\"airjordan-models\", \"fanduel_fpts_model.cbm\", file.name)\n",
    "    model = CatBoostRegressor().load_model(file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    features = pd.read_sql(\"select * from dfs_model_features\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(\n",
    "    data=features.pipe(lambda x: x[[col for col in x.columns if col not in player_game_stats.columns]]),\n",
    ")\n",
    "\n",
    "features = features.assign(prediction=model.predict(pool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_df = (\n",
    "    upcoming_df\n",
    "    .sort_values(by=[\"game_id\", \"team_id\", \"player_id\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "features = (\n",
    "    features\n",
    "    .sort_values(by=[\"game_id\", \"team_id\", \"player_id\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "matches = upcoming_df.eq(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_df[~matches[\"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[~matches[\"prediction\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:airjordan]",
   "language": "python",
   "name": "conda-env-airjordan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
